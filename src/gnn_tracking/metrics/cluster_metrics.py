from __future__ import annotations

import functools
from collections import Counter
from typing import Callable, Iterable, Protocol, TypedDict

import numpy as np
import pandas as pd
from sklearn import metrics

from gnn_tracking.utils.math import zero_division_gives_nan
from gnn_tracking.utils.nomenclature import denote_pt
from gnn_tracking.utils.signature import tolerate_additional_kwargs


class ClusterMetricType(Protocol):
    """Function type that calculates a clustering metric."""

    def __call__(
        self,
        *,
        truth: np.ndarray,
        predicted: np.ndarray,
        pts: np.ndarray,
        reconstructable: np.ndarray,
        pt_thlds: list[float],
    ) -> float | dict[str, float]:
        ...


class CustomMetrics(TypedDict):
    """Custom cluster metrics for tracking."""

    #: True number of particles
    n_particles: int
    #: Number of clusters/number of predicted particles
    n_clusters: int
    #: Number of reconstructed tracks (clusters) containing only hits from the same
    #: particle and #: every hit generated by that particle, divided by the true number
    #: of particles
    perfect: float
    #: The number of reconstructed tracks containing over 50% of hits from the same
    #: particle and over 50% of that particleâ€™s hits, divided by the total number of
    #: true particles
    double_majority: float
    #: The number of reconstructed tracks containing over 75% of hits from the same
    #: particle, divided by the total number reconstructed tracks (clusters)
    lhc: float


_custom_metrics_nan_results: CustomMetrics = {
    "n_particles": 0,
    "n_clusters": 0,
    "perfect": float("nan"),
    "lhc": float("nan"),
    "double_majority": float("nan"),
}


def custom_metrics(
    *,
    truth: np.ndarray,
    predicted: np.ndarray,
    pts: np.ndarray,
    reconstructable: np.ndarray,
    pt_thlds: Iterable[float],
) -> dict[float, CustomMetrics]:
    """Calculate 'custom' metrics for matching tracks and hits.

    Args:
        truth: Truth labels/PIDs for each hit
        predicted: Predicted labels/cluster index for each hit. Negative labels are
            interpreted as noise (because this is how DBSCAN outputs it) and are
            ignored
        pts: pt values of the hits
        reconstructable: Whether the hit belongs to a "reconstructable tracks" (this
            usually implies a cut on the number of layers that are being hit
            etc.)
        pt_thlds: pt thresholds to calculate the metrics for

    Returns:
        See `CustomMetrics`
    """
    assert predicted.shape == truth.shape == pts.shape, (
        predicted.shape,
        truth.shape,
        pts.shape,
    )
    if len(truth) == 0:
        return {pt: _custom_metrics_nan_results for pt in pt_thlds}
    df = pd.DataFrame({"c": predicted, "id": truth, "pt": pts, "r": reconstructable})

    # For each cluster, we determine the true PID that is associated with the most
    # hits in that cluster.
    # Here we make use of the fact that `df.value_counts` sorts by the count.
    # That means that if we group by the cluster and take the first line
    # for each of the counts, we have the most popular PID for each cluster.
    # The resulting dataframe now has both the most popular PID ("id" column) and the
    # number of times it appears ("0" column).
    # This strategy is a significantly (!) faster version than doing
    # c_id.groupby("c").agg(lambda x: x.mode()[0]) etc.
    pid_counts = df[["c", "id"]].value_counts().reset_index()
    maj_df = pid_counts.groupby("c").first()
    # For each cluster: Which true PID has the most hits?
    c_maj_pids = maj_df["id"]
    # For each cluster: How many hits does the PID with the most hits have?
    c_maj_hits = maj_df[0]
    # Number of hits per cluster
    c_sizes = pid_counts.groupby("c")[0].sum()
    # Assume that negative cluster labels mean that the cluster was labeled as
    # invalid
    h_valid_cluster = predicted >= 0
    c_valid_cluster = np.unique(predicted) >= 0

    # Properties associated to PID. This is pretty trivial, but since everything is
    # passed by, rather than by PID, we need to get rid of "duplicates"
    pid_to_props = df[["id", "pt", "r"]].groupby("id")[["pt", "r"]].first()
    pid_to_pt = pid_to_props["pt"].to_dict()
    pid_to_r = pid_to_props["r"].to_dict()
    # For each cluster: Of which pt is the PID with the most hits?
    c_maj_pts = c_maj_pids.map(pid_to_pt)
    # For each cluster: Is the PID with the most hits reconstructable?
    c_maj_reconstructable = c_maj_pids.map(pid_to_r)

    # For each PID: Number of hits (in any cluster)
    pid_to_count = Counter(truth)
    # For each cluster: Take most popular PID of that cluster and get number of hits of
    # that PID (in any cluster)
    maj_hits = c_maj_pids.map(pid_to_count)

    result = dict[float, ClusterMetricType]()
    for pt in pt_thlds:
        c_mask = (c_maj_pts >= pt) & c_maj_reconstructable

        # For each cluster: Fraction of hits that have the most popular PID
        c_maj_frac = (c_maj_hits[c_mask] / c_sizes[c_mask]).fillna(0)
        # For each cluster: Take the most popular PID of that cluster. What fraction of
        # the corresponding hits is in this cluster?
        maj_frac = (c_maj_hits[c_mask] / maj_hits[c_mask]).fillna(0)

        perfect_match: np.ndarray = (
            (maj_hits[c_mask] == c_maj_hits[c_mask])
            & (c_maj_frac > 0.99)
            & c_valid_cluster[c_mask]
        )
        double_majority: np.ndarray = (
            (maj_frac > 0.5) & (c_maj_frac > 0.5) & c_valid_cluster[c_mask]
        )
        lhc_match: np.ndarray = (c_maj_frac > 0.75) & c_valid_cluster[c_mask]

        h_pt_mask = pts >= pt
        n_particles = len(np.unique(truth[h_pt_mask]))
        n_clusters = len(np.unique(predicted[h_pt_mask & h_valid_cluster]))

        r = {
            "n_particles": n_particles,
            "n_clusters": n_clusters,
            "perfect": zero_division_gives_nan(sum(perfect_match), n_particles),
            "double_majority": zero_division_gives_nan(
                sum(double_majority), n_particles
            ),
            "lhc": zero_division_gives_nan(sum(lhc_match), n_clusters),
        }
        result[pt] = r  # type: ignore
    return result  # type: ignore


def custom_metrics_flattened(*args, **kwargs) -> dict[str, float]:
    """Flatten the result of `custom_metrics` by using pt suffixes to arrive at a
    flat dictionary, rather than a nested one."""
    return {
        denote_pt(k, pt): v
        for pt, results in custom_metrics(*args, **kwargs).items()
        for k, v in results.items()
    }


def count_hits_per_cluster(predicted: np.ndarray) -> np.ndarray:
    """Count number of hits per cluster"""
    _, counts = np.unique(predicted, return_counts=True)
    hist_counts, _ = np.histogram(counts, bins=np.arange(0.5, counts.max() + 1.5))
    return hist_counts


def hits_per_cluster_count_to_flat_dict(
    counts: np.ndarray, min_max=10
) -> dict[str, float]:
    """Turn result array from `count_hits_per_cluster` into a dictionary
    with cumulative counts.

    Args:
        counts: Result from `count_hits_per_cluster`
        min_max: Pad the counts with zeros to at least this length
    """
    cumulative = np.cumsum(
        np.pad(counts, (0, max(0, min_max - len(counts))), "constant")
    )
    total = cumulative[-1]
    return {
        f"hitcountgeq_{i:04}": cumulative / total
        for i, cumulative in enumerate(reversed(cumulative), start=1)
    }


def _sklearn_signature_wrap(func: Callable) -> ClusterMetricType:
    """A decorator to make an sklearn cluster metric function accept/take the
    arguments from ``ClusterMetricType``.
    """

    @functools.wraps(func)
    @tolerate_additional_kwargs
    def wrapped(predicted: np.ndarray, truth: np.ndarray):
        return func(truth, predicted)

    return wrapped


#: Common metrics that we have for clustering/matching of tracks to hits
common_metrics: dict[str, ClusterMetricType] = {
    "v_measure": _sklearn_signature_wrap(metrics.v_measure_score),
    "homogeneity": _sklearn_signature_wrap(metrics.homogeneity_score),
    "completeness": _sklearn_signature_wrap(metrics.completeness_score),
    "trk": custom_metrics_flattened,
    "adjusted_rand": _sklearn_signature_wrap(metrics.adjusted_rand_score),
    "fowlkes_mallows": _sklearn_signature_wrap(metrics.fowlkes_mallows_score),
    "adjusted_mutual_info": _sklearn_signature_wrap(metrics.adjusted_mutual_info_score),
    "trkc": lambda **kwargs: hits_per_cluster_count_to_flat_dict(
        tolerate_additional_kwargs(count_hits_per_cluster)(**kwargs)
    ),
}
